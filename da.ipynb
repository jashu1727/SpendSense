{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No   _address                                              _body  \\\n",
      "0   1  AX-FEDBNK  Rs 40.00 debited from your A/c using UPI on 01...   \n",
      "1   2  AX-FEDBNK  Rs 50.00 debited from your A/c using UPI on 01...   \n",
      "2   3  AD-FEDBNK  Rs 75.00 debited from your A/c using UPI on 01...   \n",
      "3   4  AD-FEDBNK  Rs 200.00 debited from your A/c using UPI on 0...   \n",
      "4   5  AX-FEDBNK  Rs 255.00 debited from your A/c using UPI on 0...   \n",
      "\n",
      "               date  \n",
      "0  01-08-2023 08:51  \n",
      "1  01-08-2023 11:56  \n",
      "2  01-08-2023 12:05  \n",
      "3  01-08-2023 17:09  \n",
      "4  02-08-2023 16:25  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt to load the CSV file with ISO-8859-1 encoding\n",
    "    df = pd.read_csv('finaldata.csv', encoding='ISO-8859-1')\n",
    "    print(df.head())  # Display the first few rows to check the content\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No   _address                                              _body  \\\n",
      "0   1  AX-FEDBNK  Rs 40.00 debited from your A/c using UPI on 01...   \n",
      "1   2  AX-FEDBNK  Rs 50.00 debited from your A/c using UPI on 01...   \n",
      "2   3  AD-FEDBNK  Rs 75.00 debited from your A/c using UPI on 01...   \n",
      "3   4  AD-FEDBNK  Rs 200.00 debited from your A/c using UPI on 0...   \n",
      "4   5  AX-FEDBNK  Rs 255.00 debited from your A/c using UPI on 0...   \n",
      "\n",
      "               date  Amount   Action  \n",
      "0  01-08-2023 08:51   40.00  debited  \n",
      "1  01-08-2023 11:56   50.00  debited  \n",
      "2  01-08-2023 12:05   75.00  debited  \n",
      "3  01-08-2023 17:09  200.00  debited  \n",
      "4  02-08-2023 16:25  255.00  debited  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a function to extract amount and action from the message\n",
    "def extract_details(text):\n",
    "    # Regex to find the amount pattern and the action \"debited\"\n",
    "    amount_match = re.search(r'Rs (\\d+\\.?\\d*)', text)\n",
    "    action_match = re.search(r'(debited|credited)', text, re.IGNORECASE)\n",
    "\n",
    "    amount = amount_match.group(1) if amount_match else None\n",
    "    action = action_match.group(1).lower() if action_match else None\n",
    "    return pd.Series([amount, action])\n",
    "\n",
    "# Apply the function to the '_body' column and create new columns\n",
    "df[['Amount', 'Action']] = df['_body'].apply(extract_details)\n",
    "\n",
    "# Show the modified DataFrame\n",
    "print(df[['No', '_address', '_body', 'date', 'Amount', 'Action']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No   _address                                              _body  \\\n",
      "0   1  AX-FEDBNK  Rs 40.00 debited from your A/c using UPI on 01...   \n",
      "1   2  AX-FEDBNK  Rs 50.00 debited from your A/c using UPI on 01...   \n",
      "2   3  AD-FEDBNK  Rs 75.00 debited from your A/c using UPI on 01...   \n",
      "3   4  AD-FEDBNK  Rs 200.00 debited from your A/c using UPI on 0...   \n",
      "4   5  AX-FEDBNK  Rs 255.00 debited from your A/c using UPI on 0...   \n",
      "\n",
      "               date  Amount   Action  Transaction_Type  \n",
      "0  01-08-2023 08:51   40.00  debited                 0  \n",
      "1  01-08-2023 11:56   50.00  debited                 0  \n",
      "2  01-08-2023 12:05   75.00  debited                 0  \n",
      "3  01-08-2023 17:09  200.00  debited                 0  \n",
      "4  02-08-2023 16:25  255.00  debited                 0  \n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'Transaction_Type' based on the 'Action' column\n",
    "df['Transaction_Type'] = df['Action'].apply(lambda x: 1 if x == 'credited' else 0)\n",
    "\n",
    "# Show the modified DataFrame with the new binary column\n",
    "print(df[['No', '_address', '_body', 'date', 'Amount', 'Action', 'Transaction_Type']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No                    0\n",
      "_address              0\n",
      "_body                 0\n",
      "date                  0\n",
      "Amount              594\n",
      "Action              234\n",
      "Transaction_Type      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handling missing values\n",
    "# For numerical columns, fill missing values with the median or meandf['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "df['Amount'] = df['Amount'].fillna(df['Amount'].median())\n",
    "\n",
    "# For categorical columns, you might consider filling missing values with the mode or a placeholder like 'Unknown'\n",
    "df['Action'] = df['Action'].fillna(df['Action'].mode()[0])\n",
    "\n",
    "# If 'Action' has very few missing values, consider dropping those rows\n",
    "df.dropna(subset=['Action'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Action' is the only categorical variable that needs encoding\n",
    "df['Action_Code'] = df['Action'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "df['Amount_Normalized'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "df['Amount_Standardized'] = scaler.fit_transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No   _address                                              _body  \\\n",
      "0   1  AX-FEDBNK  Rs 40.00 debited from your A/c using UPI on 01...   \n",
      "1   2  AX-FEDBNK  Rs 50.00 debited from your A/c using UPI on 01...   \n",
      "2   3  AD-FEDBNK  Rs 75.00 debited from your A/c using UPI on 01...   \n",
      "3   4  AD-FEDBNK  Rs 200.00 debited from your A/c using UPI on 0...   \n",
      "4   5  AX-FEDBNK  Rs 255.00 debited from your A/c using UPI on 0...   \n",
      "\n",
      "               date  Amount   Action  Transaction_Type  Action_Code  \\\n",
      "0  01-08-2023 08:51    40.0  debited                 0            1   \n",
      "1  01-08-2023 11:56    50.0  debited                 0            1   \n",
      "2  01-08-2023 12:05    75.0  debited                 0            1   \n",
      "3  01-08-2023 17:09   200.0  debited                 0            1   \n",
      "4  02-08-2023 16:25   255.0  debited                 0            1   \n",
      "\n",
      "   Amount_Normalized  Amount_Standardized  \n",
      "0           0.001444            -0.163380  \n",
      "1           0.001815            -0.155692  \n",
      "2           0.002741            -0.136473  \n",
      "3           0.007371            -0.040375  \n",
      "4           0.009408             0.001908  \n"
     ]
    }
   ],
   "source": [
    "# Review the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Export the cleaned and preprocessed DataFrame\n",
    "df.to_csv('finaldata_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-01-08 08:51:00\n",
      "1   2023-01-08 11:56:00\n",
      "2   2023-01-08 12:05:00\n",
      "3   2023-01-08 17:09:00\n",
      "4   2023-02-08 16:25:00\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned data\n",
    "df = pd.read_csv('finaldata_cleaned.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Adjust format if necessary\n",
    "\n",
    "# Check the conversion\n",
    "print(df['date'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from the date for grouping data later\n",
    "df['Year'] = df['date'].dt.year\n",
    "df['Month'] = df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month  Total_Spend  Average_Spend\n",
      "0  2023.0    1.0      1927.95     148.303846\n",
      "1  2023.0    2.0       320.00      80.000000\n",
      "2  2023.0    3.0      1574.00     131.166667\n",
      "3  2023.0    4.0       262.00      52.400000\n",
      "4  2023.0    5.0        45.00      45.000000\n"
     ]
    }
   ],
   "source": [
    "# Group by year and month, then summarize spending\n",
    "monthly_spend = df.groupby(['Year', 'Month'])['Amount'].agg(['sum', 'mean']).reset_index()\n",
    "monthly_spend.columns = ['Year', 'Month', 'Total_Spend', 'Average_Spend']\n",
    "\n",
    "print(monthly_spend.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Transaction Size: 252.51754468485422\n"
     ]
    }
   ],
   "source": [
    "# Overall average transaction size\n",
    "average_transaction_size = df['Amount'].mean()\n",
    "print(f\"Average Transaction Size: {average_transaction_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Action  Transaction_Count\n",
      "0   debited                938\n",
      "1  credited                125\n"
     ]
    }
   ],
   "source": [
    "# Count number of transactions per category\n",
    "transactions_per_category = df['Action'].value_counts().reset_index()\n",
    "transactions_per_category.columns = ['Action', 'Transaction_Count']\n",
    "\n",
    "print(transactions_per_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging monthly data back to the main DataFrame (if necessary)\n",
    "df = df.merge(monthly_spend, on=['Year', 'Month'], how='left')\n",
    "\n",
    "# Save the enhanced DataFrame\n",
    "df.to_csv('finaldata_enhanced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_18044\\1297187390.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Amount'].fillna(df['Amount'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean or median\n",
    "df['Amount'].fillna(df['Amount'].median(), inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_by_amount(amount):\n",
    "    if amount < 50:\n",
    "        return 'Miscellaneous'\n",
    "    elif 100 <= amount < 500:\n",
    "        return 'Food/Fuel/Shopping'\n",
    "    elif amount >= 500:\n",
    "        return 'Rent/High-Value Purchases'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Ensure the 'Amount' column is numeric\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['Amount_Category'] = df['Amount'].apply(categorize_by_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Amount     Amount_Category\n",
      "0    40.0       Miscellaneous\n",
      "1    50.0               Other\n",
      "2    75.0               Other\n",
      "3   200.0  Food/Fuel/Shopping\n",
      "4   255.0  Food/Fuel/Shopping\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'Amount' column is numeric\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['Amount_Category'] = df['Amount'].apply(categorize_by_amount)\n",
    "\n",
    "# Check the new categorization\n",
    "print(df[['Amount', 'Amount_Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount_Category\n",
      "Other                        676\n",
      "Miscellaneous                185\n",
      "Food/Fuel/Shopping           134\n",
      "Rent/High-Value Purchases     68\n",
      "Name: count, dtype: int64\n",
      "Amount_Category\n",
      "Food/Fuel/Shopping            198.090000\n",
      "Miscellaneous                  24.605135\n",
      "Other                          69.656805\n",
      "Rent/High-Value Purchases    2797.678529\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of transactions per category\n",
    "category_counts = df['Amount_Category'].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "# Mean spending per category\n",
    "mean_spending = df.groupby('Amount_Category')['Amount'].mean()\n",
    "print(mean_spending)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact list retrieval\n",
    "import pandas as pd\n",
    "\n",
    "# Load transaction data\n",
    "df_transactions = pd.read_csv('/mnt/data/finaldata_enhanced.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Load contact list - replace 'path_to_contact_list.csv' with the actual path\n",
    "df_contacts = pd.read_csv('path_to_contact_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PhoneNumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PhoneNumber'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming the correct column name is 'PhoneNumber'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_contacts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhoneNumber\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_contacts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhoneNumber\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_contacts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhoneNumber\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_contacts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhoneNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+91\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Removing country code if present\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Handling Missing Values\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\heman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PhoneNumber'"
     ]
    }
   ],
   "source": [
    "# Assuming the correct column name is 'PhoneNumber'\n",
    "df_contact['PhoneNumber'] = df_contact['PhoneNumber'].str.replace(' ', '').str.replace('-', '').str.replace('(', '').str.replace(')', '')\n",
    "df_contact['PhoneNumber'] = df_contact['PhoneNumber'].str.replace('+91', '')  # Removing country code if present\n",
    "\n",
    "# Handling Missing Values\n",
    "df_contacts.dropna(subset=['Name', 'PhoneNumber'], inplace=True)  # Adjust to the actual column name\n",
    "\n",
    "# Removing Duplicates\n",
    "df_contacts.drop_duplicates(subset=['PhoneNumber'], keep='first', inplace=True)  # Adjust to the actual column name\n",
    "\n",
    "# Correcting Names to title case for uniformity\n",
    "df_contacts['Name'] = df_contacts['Name'].str.title()\n",
    "\n",
    "# Save the cleaned data\n",
    "df_contacts.to_csv('cleaned_contacts.csv', index=False)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(df_contacts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name Mobile Phone\n",
      "0  Samsung Helpline  1.80041E+12\n",
      "1      Naresh Mamma  9.19308E+11\n",
      "2  Harsh Gautam SVM  9.18605E+11\n",
      "3           Dada Ji   9450139031\n",
      "4           Nana Ji  9.19415E+11\n",
      "\n",
      "Missing Values in Each Column:\n",
      "Name              5\n",
      "Mobile Phone    874\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Entries Check:\n",
      "999\n",
      "\n",
      "Data Summary:\n",
      "        Name Mobile Phone\n",
      "count   1775          906\n",
      "unique  1773          780\n",
      "top     Kush        53432\n",
      "freq       2            8\n",
      "               Name Mobile Phone\n",
      "0  Samsung Helpline            1\n",
      "1      Naresh Mamma            9\n",
      "3           Dada Ji   9450139031\n",
      "5       Canera Bank   7312566641\n",
      "6     Sachin Chacha   9935161683\n",
      "\n",
      "Data Summary:\n",
      "                  Name Mobile Phone\n",
      "count              454          454\n",
      "unique             453          454\n",
      "top     AL hello tunes            1\n",
      "freq                 2            1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_18044\\2698033285.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_contacts['Name'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Contacts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the contact file\n",
    "df_contacts = pd.read_csv('contact.csv')\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df_contacts.head())\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(df_contacts.isnull().sum())\n",
    "\n",
    "# Check for duplicate entries based on the 'Mobile Phone' column\n",
    "print(\"\\nDuplicate Entries Check:\")\n",
    "print(df_contacts.duplicated(subset=['Mobile Phone']).sum())\n",
    "\n",
    "# Print basic statistics to understand the data better\n",
    "print(\"\\nData Summary:\")\n",
    "print(df_contacts.describe(include='all'))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data ensuring phone numbers are read as strings\n",
    "df_contacts = pd.read_csv('C:\\\\Users\\\\heman\\\\Desktop\\\\SpendSense\\\\contact.csv', dtype={'Mobile Phone': str})\n",
    "\n",
    "# Check for formatting issues and attempt to clean\n",
    "df_contacts['Mobile Phone'] = df_contacts['Mobile Phone'].apply(lambda x: x.split('.')[0] if isinstance(x, str) and '.' in x else x)\n",
    "\n",
    "# Optionally, remove rows with missing mobile phone numbers if the phone number is essential\n",
    "df_contacts.dropna(subset=['Mobile Phone'], inplace=True)\n",
    "\n",
    "# Fill missing names with a placeholder if needed\n",
    "df_contacts['Name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Remove duplicates based on 'Mobile Phone' assuming it should be unique\n",
    "df_contacts = df_contacts.drop_duplicates(subset=['Mobile Phone'], keep='first')\n",
    "\n",
    "# Display the cleaned data\n",
    "print(df_contacts.head())\n",
    "print(\"\\nData Summary:\")\n",
    "print(df_contacts.describe(include='all'))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
